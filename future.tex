\section{Improvements}
One could use a multithreading BLAS library to have a more uniform comparison between BLAS and cuBLAS. One could extend the code from square matrices that can me regularly filled on each node to rectangular matrices of any size. Using the SUMMA algorithm instead of Cannons algorithm should improve performance. Then, one could do a lot of measurements with different matrix sizes and shapes with BLAS and cuBLAS and with this data create a code that balances CPU and GPU usage well on each node depending on the matrix sizes. Overlapping communication and computation on the GPU would also improve the performance significantly. This would increase the memory requirements even more.
